{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is a draft \n",
    "\n",
    "While writing the other code, it started to get a bit messy and difficult to understand \n",
    "this is a draft of a batch processing class which abstracts the processes of async, saving\n",
    "and recovering from a failure.\n",
    "\n",
    "It is not complete. Use the other functional method in the other notebook. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch 1: 100%|██████████| 10/10 [00:04<00:00,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 completed. Total processed: 10/10\n",
      "All processing complete. Total processed: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import pickle\n",
    "import logging\n",
    "from typing import List, Callable, Any, Optional\n",
    "import random\n",
    "import nest_asyncio\n",
    "from tqdm.asyncio import tqdm\n",
    "import sys\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Disable all logging to console\n",
    "logging.getLogger().handlers = []\n",
    "\n",
    "class BatchProcessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        process_func: Callable[[str], Any],\n",
    "        batch_size: int = 100,\n",
    "        concurrency_limit: int = 10,\n",
    "        pickle_file: str = 'progress.pickle',\n",
    "        logfile: Optional[str] = None\n",
    "    ):\n",
    "        self.process_func = process_func\n",
    "        self.batch_size = batch_size\n",
    "        self.concurrency_limit = concurrency_limit\n",
    "        self.pickle_file = pickle_file\n",
    "        self.semaphore = asyncio.Semaphore(concurrency_limit)\n",
    "        self.processed_strings = []\n",
    "        self.results = []\n",
    "\n",
    "        # Set up logging\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        self.logger.handlers = []  # Clear any existing handlers\n",
    "        formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "\n",
    "        # File handler (if logfile is provided)\n",
    "        if logfile:\n",
    "            file_handler = logging.FileHandler(logfile)\n",
    "            file_handler.setFormatter(formatter)\n",
    "            self.logger.addHandler(file_handler)\n",
    "\n",
    "    async def process_string_with_semaphore(self, job_number: int, string: str):\n",
    "        async with self.semaphore:\n",
    "            result = await self.process_func(string)\n",
    "            self.logger.info(f\"Processed job {job_number}: {string}\")\n",
    "            return result\n",
    "\n",
    "    async def process_batch(self, batch: List[str], batch_number: int, total_jobs: int):\n",
    "        batch_tasks = [self.process_string_with_semaphore(i, s) for i, s in enumerate(batch)]\n",
    "        batch_results = await tqdm.gather(*batch_tasks, desc=f\"Batch {batch_number}\")\n",
    "        \n",
    "        self.processed_strings.extend(batch)\n",
    "        self.results.extend(batch_results)\n",
    "        \n",
    "        self.save_progress()\n",
    "        \n",
    "        completion_message = f\"Batch {batch_number} completed. Total processed: {len(self.processed_strings)}/{total_jobs}\"\n",
    "        print(completion_message)\n",
    "        self.logger.info(completion_message)\n",
    "\n",
    "    def save_progress(self):\n",
    "        with open(self.pickle_file, 'wb') as f:\n",
    "            pickle.dump({'processed_strings': self.processed_strings, 'results': self.results}, f)\n",
    "\n",
    "    async def process_strings_in_batches(self, input_strings: List[str]):\n",
    "        total_jobs = len(input_strings)\n",
    "        \n",
    "        for i in range(0, total_jobs, self.batch_size):\n",
    "            batch = input_strings[i:i+self.batch_size]\n",
    "            await self.process_batch(batch, i//self.batch_size + 1, total_jobs)\n",
    "\n",
    "        return self.processed_strings, self.results\n",
    "\n",
    "# Example usage\n",
    "async def example_process_single_string(string: str) -> str:\n",
    "    sleep_time = random.uniform(2, 2.5)\n",
    "    await asyncio.sleep(sleep_time)\n",
    "    return f\"Processed: {string} (took {sleep_time:.2f} seconds)\"\n",
    "\n",
    "async def main():\n",
    "    input_strings = [f\"string{i + 1}\" for i in range(10)]\n",
    "    \n",
    "    processor = BatchProcessor(\n",
    "        process_func=example_process_single_string,\n",
    "        batch_size=10,\n",
    "        concurrency_limit=5,\n",
    "        logfile=\"david_test.log\"\n",
    "    )\n",
    "    \n",
    "    processed_strings, results = await processor.process_strings_in_batches(input_strings)\n",
    "    print(f\"All processing complete. Total processed: {len(processed_strings)}\")\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.666666666666668"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.11111111111111"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4300*16)/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "form-experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
