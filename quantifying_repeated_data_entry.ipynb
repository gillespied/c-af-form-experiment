{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we use Claude to extract all the fields from a form\n",
    "\n",
    "Based on the idea from here: \n",
    "https://github.com/co-cddo/form-extractor-prototype_testing/tree/main\n",
    "\n",
    "Yes we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "# import random\n",
    "import time\n",
    "\n",
    "# from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Tuple, Union\n",
    "\n",
    "import boto3\n",
    "\n",
    "# import botocore\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from anthropic import AsyncAnthropicBedrock, RateLimitError\n",
    "from anthropic.types.message import Message\n",
    "\n",
    "# from anthropic.types.tool_use_block import ToolUseBlock\n",
    "from dotenv import load_dotenv\n",
    "from pdf2image import convert_from_path\n",
    "from pdf2image.exceptions import PDFPageCountError\n",
    "from PIL import Image\n",
    "from PIL.Image import DecompressionBombError\n",
    "from tqdm.asyncio import tqdm\n",
    "# from tqdm.notebook import tqdm as tqdm_notebook\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"form_processing.log\",\n",
    "    level=logging.INFO,  # Adjust the level as needed (e.g., INFO, DEBUG, WARNING, ERROR, CRITICAL)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filemode=\"a\",  # 'a' for append mode, 'w' for overwrite mode\n",
    ")\n",
    "logging.info(\"Setup log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing forms. Check 'form_processing.log' for detailed logs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Forms: 100%|██████████| 100/100 [12:20<00:00,  7.41s/form]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 forms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Intitiating log\")\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "boto3.setup_default_session()\n",
    "client = AsyncAnthropicBedrock()\n",
    "\n",
    "\n",
    "async def test_client(client):\n",
    "    response = await client.messages.create(\n",
    "        model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "        temperature=0.01,\n",
    "        max_tokens=2,\n",
    "        messages=[{\"role\": \"user\", \"content\": \"reply Yes. Nothing else\"}],\n",
    "    )\n",
    "\n",
    "    return response.content[0].text == \"Yes.\"\n",
    "\n",
    "\n",
    "if await test_client(client):\n",
    "    logging.info(\"Queried the model successfully.\")\n",
    "\n",
    "base_prompt = \"\"\"\n",
    "Is this a form? Answer Yes or No. \n",
    "It's only a form if it contains form field boxes.\n",
    "Hand drawn forms, questionnaires and surveys are all valid forms.\n",
    "If it is a form, extract the questions from it using the extract_form_questions tool.\n",
    "If there is no output, explain why.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_batch_results(results_file: str) -> Dict[str, Dict]:\n",
    "    try:\n",
    "        with open(results_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        return {}\n",
    "\n",
    "def save_batch_results(results: Dict[str, Dict], results_file: str):\n",
    "    with open(results_file, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "\n",
    "\n",
    "def get_all_files(folder_path: str) -> List[Path]:\n",
    "    return list(Path(folder_path).glob(\"**/*\"))\n",
    "\n",
    "\n",
    "def pdf_to_image_bytes(pdf_path: Path, width: int = 600, dpi: int = 300):\n",
    "    # Convert PDF to list of PIL Image objects\n",
    "    logging.info(f\"Converting {pdf_path} to images\")\n",
    "    try: \n",
    "        images = convert_from_path(pdf_path, dpi=dpi)\n",
    "    except PDFPageCountError as e:\n",
    "        logging.warning(f\"{pdf_path} encountered an error return empty list {e}\")\n",
    "        return []\n",
    "    except DecompressionBombError as e:\n",
    "        logging.warn(f\"{pdf_path} encountered a decompression bomb error, returning empty list: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "    image_bytes_list = []\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        # Resize image if width is specified\n",
    "        if width:\n",
    "            ratio = width / float(img.width)\n",
    "            height = int(ratio * img.height)\n",
    "            img = img.resize((width, height), Image.LANCZOS)\n",
    "\n",
    "        # Convert PIL Image to bytes\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format=\"JPEG\")\n",
    "        img_byte_arr = img_byte_arr.getvalue()\n",
    "\n",
    "        image_bytes_list.append(img_byte_arr)\n",
    "\n",
    "    return image_bytes_list\n",
    "\n",
    "\n",
    "async def exponential_backoff(attempt, base_delay):\n",
    "    delay = base_delay * (2**attempt)\n",
    "    await asyncio.sleep(delay)\n",
    "    return delay\n",
    "\n",
    "\n",
    "def encode_image(byte_array):\n",
    "    \"\"\"encode image for claude\"\"\"\n",
    "    return base64.b64encode(byte_array).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "def format_messages(image_bytes):\n",
    "    messages = [\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"source\": {\n",
    "                \"type\": \"base64\",\n",
    "                \"media_type\": \"image/jpeg\",\n",
    "                \"data\": encode_image(img),\n",
    "            },\n",
    "        }\n",
    "        for img in image_bytes\n",
    "    ] + [{\"type\": \"text\", \"text\": base_prompt}]\n",
    "    return messages\n",
    "\n",
    "\n",
    "async def ask_claude(messages, client, extraction_tool):\n",
    "    response = await client.messages.create(\n",
    "        model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "        temperature=0.01,\n",
    "        max_tokens=5000,\n",
    "        tools=[extraction_tool],\n",
    "        messages=[{\"role\": \"user\", \"content\": messages}],\n",
    "    )\n",
    "    return {\n",
    "        \"result\": response,\n",
    "        \"input_tokens\": response.usage.input_tokens,\n",
    "        \"output_tokens\": response.usage.output_tokens,\n",
    "    }\n",
    "\n",
    "\n",
    "async def get_message_with_backoff(\n",
    "    messages, semaphore, client, extraction_tool, max_retries=5, base_delay=1\n",
    "):\n",
    "    async with semaphore:\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                return await ask_claude(messages, client, extraction_tool)\n",
    "            except RateLimitError as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    logging.exception(\n",
    "                        f\"Rate limit exceeded after {max_retries} attempts | Error: {e}\"\n",
    "                    )\n",
    "                    return {\n",
    "                        \"result\": e.status_code,\n",
    "                        \"input_tokens\": None,\n",
    "                        \"output_tokens\": None,\n",
    "                    }\n",
    "                delay = await exponential_backoff(attempt, base_delay)\n",
    "                logging.warning(f\"Rate limit hit, retrying in {delay:.2f} seconds...\")\n",
    "            except Exception as e:\n",
    "                logging.exception(f\"Exception occurred | Error: {e}\")\n",
    "                return {\"result\": str(e), \"input_tokens\": None, \"output_tokens\": None}\n",
    "\n",
    "\n",
    "async def process_form(\n",
    "    pdf_path: Path, semaphore: asyncio.Semaphore, client, extraction_tool, pbar: tqdm\n",
    ") -> Dict:\n",
    "    task_id = id(asyncio.current_task())\n",
    "\n",
    "    async with semaphore:\n",
    "        start_time = time.time()\n",
    "        active_tasks = len([task for task in asyncio.all_tasks() if not task.done()])\n",
    "        max_tasks = semaphore._value\n",
    "        logging.info(f\"start_processing:{pdf_path} (task_id: {task_id}, active_tasks: {active_tasks}/{max_tasks})\")\n",
    "\n",
    "        # Move PDF conversion inside the semaphore\n",
    "        images = pdf_to_image_bytes(pdf_path, 600, 300)\n",
    "        logging.info(\n",
    "            f\"[{time.time():.3f}] Task {task_id} - {pdf_path}: Converted to images.\"\n",
    "        )\n",
    "\n",
    "        if len(images) > 19:\n",
    "            images = images[0:19]\n",
    "            logging.info(\n",
    "                f\"[{time.time():.3f}] Task {task_id} - {pdf_path}: truncated as too long\"\n",
    "            )\n",
    "\n",
    "        messages = format_messages(images)\n",
    "\n",
    "        logging.info(f\"sending_request:{pdf_path} (task_id: {task_id}, active_tasks: {active_tasks}/{max_tasks})\")\n",
    "        result = await get_message_with_backoff(\n",
    "            messages, semaphore, client, extraction_tool\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        logging.info(f\"processing_complete:{pdf_path} (task_id: {task_id}, time: {processing_time:.2f}s)\")\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "async def process_batch(\n",
    "    batch: List[Path], semaphore: asyncio.Semaphore, client, extraction_tool\n",
    ") -> Dict[str, Dict]:\n",
    "    results = {}\n",
    "    for pdf_path in batch:\n",
    "        try:\n",
    "            result = await process_form(pdf_path, semaphore, client, extraction_tool)\n",
    "            results[str(pdf_path)] = result\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {pdf_path}: {str(e)}\")\n",
    "    return results\n",
    "\n",
    "\n",
    "async def process_forms_in_batches(\n",
    "    folder_path: str,\n",
    "    client,\n",
    "    extraction_tool,\n",
    "    batch_size: int = 10,\n",
    "    max_concurrent: int = 5,\n",
    "    results_file: str = \"batch_results.pickle\",\n",
    ") -> Dict[str, Dict]:\n",
    "    all_files = get_all_files(folder_path)\n",
    "    pdf_files = [Path(file) for file in all_files if str(file).lower().endswith(\".pdf\")]\n",
    "\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "\n",
    "    # Load existing results if any\n",
    "    results = load_batch_results(results_file)\n",
    "\n",
    "    # Filter out already processed files\n",
    "    pdf_files = [file for file in pdf_files if str(file) not in results]\n",
    "\n",
    "    # Create progress bar\n",
    "    pbar = tqdm(total=len(pdf_files), desc=\"Processing Forms\", unit=\"form\")\n",
    "\n",
    "    async def process_form_wrapper(pdf_path):\n",
    "        result = await process_form(pdf_path, semaphore, client, extraction_tool, pbar)\n",
    "        return str(pdf_path), result\n",
    "\n",
    "    for i in range(0, len(pdf_files), batch_size):\n",
    "        batch = pdf_files[i : i + batch_size]\n",
    "\n",
    "        logging.info(\n",
    "            f\"[{time.time():.3f}] Starting batch {i//batch_size + 1} of {len(pdf_files)//batch_size + 1}\"\n",
    "        )\n",
    "\n",
    "        # Process the batch asynchronously, but limit concurrency\n",
    "        batch_start_time = time.time()\n",
    "        tasks = [process_form_wrapper(pdf_path) for pdf_path in batch]\n",
    "        batch_results = dict(await asyncio.gather(*tasks))\n",
    "\n",
    "        batch_end_time = time.time()\n",
    "\n",
    "        # Update results after the batch is complete\n",
    "        results.update(batch_results)\n",
    "\n",
    "        # Save results after the entire batch is processed\n",
    "        save_batch_results(results, results_file)\n",
    "\n",
    "        batch_processing_time = batch_end_time - batch_start_time\n",
    "        logging.info(\n",
    "            f\"[{time.time():.3f}] Completed batch {i//batch_size + 1} in {batch_processing_time:.2f} seconds\"\n",
    "        )\n",
    "\n",
    "        logging.info(\n",
    "            f\"[{time.time():.3f}] Processed and saved batch {i//batch_size + 1} of {len(pdf_files)//batch_size + 1}\"\n",
    "        )\n",
    "\n",
    "    pbar.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "def run_form_processing(\n",
    "    folder_path: str,\n",
    "    client,\n",
    "    extraction_tool,\n",
    "    batch_size: int = 10,\n",
    "    max_concurrent: int = 5,\n",
    "    results_file: str = \"batch_results.pickle\",\n",
    ") -> pd.DataFrame:\n",
    "    print(\"Processing forms. Check 'form_processing.log' for detailed logs.\")\n",
    "\n",
    "    async def run_async():\n",
    "        return await process_forms_in_batches(\n",
    "            folder_path,\n",
    "            client,\n",
    "            extraction_tool,\n",
    "            batch_size,\n",
    "            max_concurrent,\n",
    "            results_file,\n",
    "        )\n",
    "\n",
    "    results = asyncio.run(run_async())\n",
    "    print(f\"Processed {len(results)} forms\")\n",
    "    return results\n",
    "\n",
    "\n",
    "with open(\"extract-form-questions.json\", \"r\") as file:\n",
    "    json_string = file.read()\n",
    "\n",
    "extraction_tool = json.loads(json_string)\n",
    "\n",
    "folder_path = \"forms_scrape\"\n",
    "results = run_form_processing(\n",
    "    folder_path=folder_path,\n",
    "    client=client,\n",
    "    extraction_tool=extraction_tool,\n",
    "    batch_size=10,\n",
    "    max_concurrent=10,\n",
    "    results_file=\"batch_results.pickle\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_batch_results(\"batch_results.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(results, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.9796240000000003)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_total(results_df):\n",
    "    total_count = results_df[['input_tokens', 'output_tokens']].sum()\n",
    "    rates_per1000 = {\"input_cost\": 0.003, \"output_cost\": 0.015}\n",
    "\n",
    "    return (total_count['input_tokens'] * rates_per1000['input_cost'] / 1000 +\n",
    "    total_count['output_tokens'] * rates_per1000['output_cost'] / 1000)\n",
    "\n",
    "compute_total(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(177.07905432000004)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = get_all_files(folder_path)\n",
    "pdf_files = [Path(file) for file in all_files if str(file).lower().endswith(\".pdf\")]\n",
    "\n",
    "compute_total(results_df) * len(pdf_files) / 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "form-experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
